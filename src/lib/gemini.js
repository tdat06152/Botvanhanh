import { GoogleGenerativeAI } from "@google/generative-ai";
import initialKnowledge from "../data/knowledge.json";

// L·∫•y danh s√°ch API Keys t·ª´ .env
const API_KEYS = import.meta.env.VITE_GEMINI_API_KEYS ? import.meta.env.VITE_GEMINI_API_KEYS.split(',') : [];
let currentKeyIndex = 0;

function getGenAI() {
  const key = API_KEYS[currentKeyIndex % API_KEYS.length];
  return new GoogleGenerativeAI(key);
}

function rotateKey() {
  currentKeyIndex = (currentKeyIndex + 1) % API_KEYS.length;
  console.log(`üîÑ ƒê√£ xoay sang API Key index: ${currentKeyIndex}`);
}

const EMB_MODEL = "gemini-embedding-001";
const CHAT_MODEL = "gemini-2.5-flash";

/**
 * T√≠nh Cosine Similarity
 */
function cosineSimilarity(vecA, vecB) {
  let dotProduct = 0;
  let mA = 0;
  let mB = 0;
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    mA += vecA[i] * vecA[i];
    mB += vecB[i] * vecB[i];
  }
  return dotProduct / (Math.sqrt(mA) * Math.sqrt(mB));
}

/**
 * L·∫•y knowledge t·ª´ localStorage ho·∫∑c file m·∫∑c ƒë·ªãnh
 */
function getKnowledge() {
  const saved = localStorage.getItem('knowledge_base');
  if (saved) return JSON.parse(saved);
  return initialKnowledge;
}

/**
 * H√†m g·ªçi API v·ªõi c∆° ch·∫ø Retry & Rotate Key
 */
async function callWithRetry(fn) {
  let attempts = 0;
  const maxAttempts = API_KEYS.length * 2;

  while (attempts < maxAttempts) {
    try {
      return await fn(getGenAI());
    } catch (error) {
      const isRateLimit = error.message?.includes('429') || error.message?.includes('503') || error.message?.includes('quota');
      if (isRateLimit) {
        rotateKey();
        attempts++;
        await new Promise(r => setTimeout(r, 1000)); // ƒê·ª£i 1s
        continue;
      }
      throw error;
    }
  }
  throw new Error("T·∫•t c·∫£ API Keys ƒë·ªÅu h·∫øt h·∫°n ho·∫∑c l·ªói.");
}

export async function computeEmbedding(text) {
  return await callWithRetry(async (genAI) => {
    const model = genAI.getGenerativeModel({ model: EMB_MODEL });
    const result = await model.embedContent(text);
    return result.embedding.values;
  });
}

async function retrieveContext(query, topK = 3) {
  const queryEmb = await computeEmbedding(query);
  const kb = getKnowledge();

  // Ch·ªâ nh·ªØng m·ª•c ƒë√£ c√≥ nh√∫ng (embedding) m·ªõi ƒë∆∞·ª£c t√¨m ki·∫øm ch√≠nh x√°c
  const scoredKB = kb.map(item => {
    if (!item.embedding) return { ...item, score: 0 };
    return {
      ...item,
      score: cosineSimilarity(queryEmb, item.embedding)
    };
  });

  return scoredKB
    .sort((a, b) => b.score - a.score)
    .slice(0, topK);
}

export async function askBot(query, history = []) {
  try {
    const hits = await retrieveContext(query);
    const relevantHits = hits.filter(h => h.score > 0.4);

    let context = "Kh√¥ng c√≥ th√¥ng tin ph√π h·ª£p.";
    if (relevantHits.length > 0) {
      context = relevantHits.map(h => `[${h.topic}] ${h.q}: ${h.a}`).join("\n---\n");
    }

    return await callWithRetry(async (genAI) => {
      const model = genAI.getGenerativeModel({
        model: CHAT_MODEL,
        systemInstruction: "B·∫°n l√† tr·ª£ l√Ω Process Bot. Tr·∫£ l·ªùi d·ª±a tr√™n CONTEXT. N·∫øu kh√¥ng c√≥, h√£y n√≥i ch∆∞a c√≥ trong t√†i li·ªáu."
      });

      let formattedHistory = history.map(msg => ({
        role: msg.role === "user" ? "user" : "model",
        parts: [{ text: msg.text }],
      }));

      const firstUserIndex = formattedHistory.findIndex(m => m.role === 'user');
      if (firstUserIndex !== -1) formattedHistory = formattedHistory.slice(firstUserIndex);
      else formattedHistory = [];

      const chat = model.startChat({ history: formattedHistory });
      const prompt = `CONTEXT:\n${context}\n\nC√ÇU H·ªéI: ${query}`;
      const result = await chat.sendMessage(prompt);
      const response = await result.response;

      return {
        text: response.text(),
        sources: relevantHits
      };
    });
  } catch (error) {
    return { text: "‚ö†Ô∏è L·ªói: " + error.message, sources: [] };
  }
}
